{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-06T13:30:20.469893Z","iopub.status.busy":"2024-02-06T13:30:20.469303Z","iopub.status.idle":"2024-02-06T13:30:21.622636Z","shell.execute_reply":"2024-02-06T13:30:21.621756Z","shell.execute_reply.started":"2024-02-06T13:30:20.469862Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/hehehe/cleandata.csv\n","/kaggle/input/kriti-24/sample_submission.csv\n","/kaggle/input/kriti-24/train.csv\n","/kaggle/input/kriti-24/test.csv\n","/kaggle/input/hello1/model1.pth\n","/kaggle/input/hello1/model2.pth\n","/kaggle/input/hello1/model4.pth\n","/kaggle/input/hello1/model5.pth\n","/kaggle/input/hello1/state.db\n","/kaggle/input/hello1/submission.csv\n","/kaggle/input/hello1/submission_ordered_new.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:30:21.625728Z","iopub.status.busy":"2024-02-06T13:30:21.62487Z","iopub.status.idle":"2024-02-06T13:30:31.592644Z","shell.execute_reply":"2024-02-06T13:30:31.591572Z","shell.execute_reply.started":"2024-02-06T13:30:21.625672Z"},"trusted":true},"outputs":[],"source":["import torch\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","import os\n","import torch\n","import re\n","import string\n","import json\n","\n","import emoji\n","import numpy as np\n","import pandas as pd\n","from sklearn import metrics\n","from bs4 import BeautifulSoup\n","import torch.nn as nn\n","import transformers\n","import torch\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:30:31.595137Z","iopub.status.busy":"2024-02-06T13:30:31.59437Z","iopub.status.idle":"2024-02-06T13:30:33.117783Z","shell.execute_reply":"2024-02-06T13:30:33.116513Z","shell.execute_reply.started":"2024-02-06T13:30:31.595094Z"},"trusted":true},"outputs":[],"source":["df=pd.read_csv('/kaggle/input/hehehe/cleandata.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:30:33.119527Z","iopub.status.busy":"2024-02-06T13:30:33.119111Z","iopub.status.idle":"2024-02-06T13:30:33.173747Z","shell.execute_reply":"2024-02-06T13:30:33.172487Z","shell.execute_reply.started":"2024-02-06T13:30:33.119495Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>q-bio.GN</th>\n","      <th>stat.AP</th>\n","      <th>q-fin.TR</th>\n","      <th>math.GR</th>\n","      <th>q-bio.NC</th>\n","      <th>math.NT</th>\n","      <th>q-fin.MF</th>\n","      <th>cs.SE</th>\n","      <th>math.LO</th>\n","      <th>...</th>\n","      <th>cs.CL</th>\n","      <th>econ.GN</th>\n","      <th>q-fin.GN</th>\n","      <th>math.ST</th>\n","      <th>econ.TH</th>\n","      <th>math.QA</th>\n","      <th>math.IT</th>\n","      <th>stat.TH</th>\n","      <th>math.CO</th>\n","      <th>q-fin.RM</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>axiomatic aspects default inference paper stud...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>extensions group infinite conjugacy classes ch...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>complexvalued cnns rf datadriven wireless devi...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>reconstruction drift diffusion transition prob...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>three classes propagation rules grs egrs codes...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>51205</th>\n","      <td>generalized fourier integral operators spaces ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>51206</th>\n","      <td>weaklysupervised 3d visual grounding visual li...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>51207</th>\n","      <td>strongly pseudoconvex handlebodies explicit co...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>51208</th>\n","      <td>improving endtoend speech processing efficient...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>51209</th>\n","      <td>second class particles microscopic characteris...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>51210 rows × 58 columns</p>\n","</div>"],"text/plain":["                                                    Text  q-bio.GN  stat.AP  \\\n","0      axiomatic aspects default inference paper stud...         0        0   \n","1      extensions group infinite conjugacy classes ch...         0        0   \n","2      complexvalued cnns rf datadriven wireless devi...         0        0   \n","3      reconstruction drift diffusion transition prob...         0        0   \n","4      three classes propagation rules grs egrs codes...         0        0   \n","...                                                  ...       ...      ...   \n","51205  generalized fourier integral operators spaces ...         0        0   \n","51206  weaklysupervised 3d visual grounding visual li...         0        0   \n","51207  strongly pseudoconvex handlebodies explicit co...         0        0   \n","51208  improving endtoend speech processing efficient...         0        0   \n","51209  second class particles microscopic characteris...         0        0   \n","\n","       q-fin.TR  math.GR  q-bio.NC  math.NT  q-fin.MF  cs.SE  math.LO  ...  \\\n","0             0        0         0        0         0      0        0  ...   \n","1             0        1         0        0         0      0        0  ...   \n","2             0        0         0        0         0      0        0  ...   \n","3             0        0         0        0         0      0        0  ...   \n","4             0        0         0        0         0      0        0  ...   \n","...         ...      ...       ...      ...       ...    ...      ...  ...   \n","51205         0        0         0        0         0      0        0  ...   \n","51206         0        0         0        0         0      0        0  ...   \n","51207         0        0         0        0         0      0        0  ...   \n","51208         0        0         0        0         0      0        0  ...   \n","51209         0        0         0        0         0      0        0  ...   \n","\n","       cs.CL  econ.GN  q-fin.GN  math.ST  econ.TH  math.QA  math.IT  stat.TH  \\\n","0          0        0         0        0        0        0        0        0   \n","1          0        0         0        0        0        0        0        0   \n","2          0        0         0        0        0        0        1        0   \n","3          0        0         0        1        0        0        0        1   \n","4          0        0         0        0        0        0        1        0   \n","...      ...      ...       ...      ...      ...      ...      ...      ...   \n","51205      0        0         0        0        0        0        0        0   \n","51206      1        0         0        0        0        0        0        0   \n","51207      0        0         0        0        0        0        0        0   \n","51208      1        0         0        0        0        0        0        0   \n","51209      0        0         0        0        0        0        0        0   \n","\n","       math.CO  q-fin.RM  \n","0            0         0  \n","1            0         0  \n","2            0         0  \n","3            0         0  \n","4            0         0  \n","...        ...       ...  \n","51205        0         0  \n","51206        0         0  \n","51207        0         0  \n","51208        0         0  \n","51209        0         0  \n","\n","[51210 rows x 58 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:30:33.176455Z","iopub.status.busy":"2024-02-06T13:30:33.176086Z","iopub.status.idle":"2024-02-06T13:30:33.219529Z","shell.execute_reply":"2024-02-06T13:30:33.218273Z","shell.execute_reply.started":"2024-02-06T13:30:33.176423Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 51210 entries, 0 to 51209\n","Data columns (total 58 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Text      51210 non-null  object\n"," 1   q-bio.GN  51210 non-null  int64 \n"," 2   stat.AP   51210 non-null  int64 \n"," 3   q-fin.TR  51210 non-null  int64 \n"," 4   math.GR   51210 non-null  int64 \n"," 5   q-bio.NC  51210 non-null  int64 \n"," 6   math.NT   51210 non-null  int64 \n"," 7   q-fin.MF  51210 non-null  int64 \n"," 8   cs.SE     51210 non-null  int64 \n"," 9   math.LO   51210 non-null  int64 \n"," 10  econ.EM   51210 non-null  int64 \n"," 11  q-fin.PM  51210 non-null  int64 \n"," 12  cs.CE     51210 non-null  int64 \n"," 13  q-bio.MN  51210 non-null  int64 \n"," 14  cs.CV     51210 non-null  int64 \n"," 15  math.PR   51210 non-null  int64 \n"," 16  eess.SP   51210 non-null  int64 \n"," 17  math.AT   51210 non-null  int64 \n"," 18  cs.SD     51210 non-null  int64 \n"," 19  stat.CO   51210 non-null  int64 \n"," 20  q-fin.EC  51210 non-null  int64 \n"," 21  cs.OS     51210 non-null  int64 \n"," 22  q-fin.CP  51210 non-null  int64 \n"," 23  q-bio.CB  51210 non-null  int64 \n"," 24  cs.DC     51210 non-null  int64 \n"," 25  eess.IV   51210 non-null  int64 \n"," 26  q-bio.BM  51210 non-null  int64 \n"," 27  math.CV   51210 non-null  int64 \n"," 28  stat.ML   51210 non-null  int64 \n"," 29  eess.AS   51210 non-null  int64 \n"," 30  stat.ME   51210 non-null  int64 \n"," 31  cs.LO     51210 non-null  int64 \n"," 32  cs.DM     51210 non-null  int64 \n"," 33  cs.GT     51210 non-null  int64 \n"," 34  cs.RO     51210 non-null  int64 \n"," 35  cs.IR     51210 non-null  int64 \n"," 36  cs.PL     51210 non-null  int64 \n"," 37  cs.CR     51210 non-null  int64 \n"," 38  math.AC   51210 non-null  int64 \n"," 39  cs.IT     51210 non-null  int64 \n"," 40  cs.AR     51210 non-null  int64 \n"," 41  cs.AI     51210 non-null  int64 \n"," 42  q-bio.TO  51210 non-null  int64 \n"," 43  cs.LG     51210 non-null  int64 \n"," 44  q-fin.PR  51210 non-null  int64 \n"," 45  math.AP   51210 non-null  int64 \n"," 46  cs.NI     51210 non-null  int64 \n"," 47  cs.DB     51210 non-null  int64 \n"," 48  cs.CL     51210 non-null  int64 \n"," 49  econ.GN   51210 non-null  int64 \n"," 50  q-fin.GN  51210 non-null  int64 \n"," 51  math.ST   51210 non-null  int64 \n"," 52  econ.TH   51210 non-null  int64 \n"," 53  math.QA   51210 non-null  int64 \n"," 54  math.IT   51210 non-null  int64 \n"," 55  stat.TH   51210 non-null  int64 \n"," 56  math.CO   51210 non-null  int64 \n"," 57  q-fin.RM  51210 non-null  int64 \n","dtypes: int64(57), object(1)\n","memory usage: 22.7+ MB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Specify the list of columns you want to check for 1s\n","columns_to_check = ['q-bio.GN', 'q-fin.TR', 'q-bio.NC', 'q-fin.MF', 'q-fin.PM', 'cs.CE', 'q-bio.MN', 'math.AT',\n","                    'stat.CO', 'q-fin.EC', 'cs.OS', 'q-fin.CP', 'q-bio.CB', 'q-bio.BM', 'cs.DM', 'cs.GT', 'cs.AR',\n","                    'q-bio.TO', 'q-fin.PR', 'econ.GN', 'q-fin.GN', 'econ.TH', 'q-fin.RM']\n","\n","# Create a mask to identify rows where at least one of the specified columns has a value of 1\n","mask = df[columns_to_check].any(axis=1)\n","\n","# Filter the DataFrame to keep only the rows where the mask is True\n","filtered_df = df[mask]\n","\n","# If you want to drop the original columns that were checked, you can use:\n","# filtered_df = filtered_df.drop(columns=columns_to_check)\n","\n","# Now, filtered_df contains only the rows where at least one of the specified columns has a value of 1\n","print(filtered_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["filtered_df.reset_index(drop=True, inplace=True)\n","\n","# The 'drop=True' argument will drop the old index, and 'inplace=True' will modify the DataFrame in place.\n","\n","# Now, the filtered_df has a reset index starting from 0.\n","print(filtered_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# Calculate the frequency of each class\n","class_frequencies = filtered_df.iloc[:, 1:-1].sum().sort_values(ascending=False)\n","\n","# Plot class frequencies\n","plt.figure(figsize=(12, 8))\n","class_frequencies.plot(kind='bar')\n","plt.title('Frequency of Each Class')\n","plt.xlabel('Class')\n","plt.ylabel('Frequency')\n","plt.xticks(rotation=90)\n","plt.show()\n","\n","class_frequencies"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Assuming `df` is your DataFrame and `columns_to_check` is your list of columns\n","# Create a mask to identify rows where all specified columns do not have a value of 1\n","mask = df[columns_to_check].sum(axis=1) == 0\n","\n","# Use the mask to filter the DataFrame\n","df_majority = df[mask]\n","\n","# Now `df_filtered` contains rows where none of the specified columns have a value of 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_majority.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_majority"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Calculate the frequency of each class\n","class_frequencies = df_majority.iloc[:, 1:-1].sum().sort_values(ascending=False)\n","\n","# Plot class frequencies\n","plt.figure(figsize=(12, 8))\n","class_frequencies.plot(kind='bar')\n","plt.title('Frequency of Each Class')\n","plt.xlabel('Class')\n","plt.ylabel('Frequency')\n","plt.xticks(rotation=90)\n","plt.show()\n","\n","class_frequencies"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["target_cols = [col for col in df.columns if col not in ['Text']]\n","len(target_cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MAX_LEN = 200\n","TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 32\n","EPOCHS = 10\n","LEARNING_RATE = 3e-9\n","tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# class BERTDataset(Dataset):\n","#     def __init__(self, df, tokenizer, max_len):\n","#         self.df = df\n","#         self.max_len = max_len\n","#         self.text = df.Text\n","#         self.tokenizer = tokenizer\n","#         self.targets = df[target_cols].values\n","        \n","#     def __len__(self):\n","#         return len(self.df)\n","    \n","#     def __getitem__(self, index):\n","#         text = self.text[index]\n","#         inputs = self.tokenizer.encode_plus(\n","#             text,\n","#             truncation=True,\n","#             add_special_tokens=True,\n","#             max_length=self.max_len,\n","#             padding='max_length',\n","#             return_token_type_ids=True\n","#         )\n","#         ids = inputs['input_ids']\n","#         mask = inputs['attention_mask']\n","#         token_type_ids = inputs[\"token_type_ids\"]\n","        \n","#         return {\n","#             'ids': torch.tensor(ids, dtype=torch.long),\n","#             'mask': torch.tensor(mask, dtype=torch.long),\n","#             'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","#             'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","#         }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# train_dataset_minor = BERTDataset(df, tokenizer, MAX_LEN)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# majority = DataLoader(train_dataset_minor, batch_size=TRAIN_BATCH_SIZE, \n","#                           num_workers=4, shuffle=True, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import torch\n","# import pandas as pd\n","# from torch.utils.data import Dataset, DataLoader\n","# from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","# from sklearn.metrics import accuracy_score, f1_score\n","# from sklearn.model_selection import train_test_split\n","# from transformers import AutoModel\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# class MultiLabelSciBERT(torch.nn.Module):\n","#     def __init__(self, num_labels):\n","#         super(MultiLabelSciBERT, self).__init__()\n","#         self.sci_bert = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n","#         self.classifier = torch.nn.Linear(768, num_labels)\n","\n","#     def forward(self, ids,mask):\n","#         outputs = self.sci_bert(ids, attention_mask=mask)\n","#         sequence_output = outputs[0][:, 0, :]  \n","#         return self.classifier(sequence_output)\n","    \n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# FROM HERE FOR INFERENCE"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_news= MultiLabelSciBERT(57)\n","model_path = '/kaggle/input/hello1/model5.pth'\n","loaded_st = torch.load(model_path)\n","model_news.load_state_dict(loaded_st)\n","model_news.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def validation():\n","#     model_news.eval() \n","#     fin_targets=[]\n","#     fin_outputs=[]\n","#     with torch.no_grad():\n","#         for _, data in enumerate(majority, 0):\n","#             ids = data['ids'].to(device, dtype = torch.long)\n","#             mask = data['mask'].to(device, dtype = torch.long)\n","#             token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","#             targets = data['targets'].to(device, dtype = torch.float)\n","#             outputs = model_news(ids, mask)\n","# #              outputs = model(ids, mask)\n","#             fin_targets.extend(targets.cpu().detach().numpy().tolist())\n","#             fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","#     return fin_outputs, fin_targets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import torch\n","# from torch.cuda.amp import autocast\n","# import torch\n","# from torch.cuda.amp import GradScaler\n","\n","# # Define the GradScaler object\n","# scaler = GradScaler()\n","# def train(epoch):\n","#     model_news.train()\n","#     for _, data in enumerate(majority, 0):\n","#         ids = data['ids'].to(device, dtype=torch.long)\n","#         mask = data['mask'].to(device, dtype=torch.long)\n","#         targets = data['targets'].to(device, dtype=torch.float)\n","\n","#         optimizer.zero_grad()\n","\n","#         with autocast():\n","#             outputs = model_news(ids, mask)\n","#             loss = loss_fn(outputs, targets )\n","\n","#         scaler.scale(loss).backward()\n","#         scaler.step(optimizer)\n","#         scaler.update()\n","\n","#         if _ % 500 == 0:\n","#             print(f'Epoch: {epoch}, Loss: {loss.item()}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.optim import AdamW\n","optimizer = AdamW(model_news.parameters(), lr=LEARNING_RATE, weight_decay=1e-6)\n","\n","def loss_fn(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# for epoch in range(EPOCHS):\n","#     train(epoch) "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def validation():\n","#     model_news.eval() \n","#     fin_targets=[]\n","#     fin_outputs=[]\n","#     with torch.no_grad():\n","#         for _, data in enumerate(majority, 0):\n","#             ids = data['ids'].to(device, dtype = torch.long)\n","#             mask = data['mask'].to(device, dtype = torch.long)\n","#             token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","#             targets = data['targets'].to(device, dtype = torch.float)\n","#             outputs = model_news(ids, mask)\n","# #              outputs = model(ids, mask)\n","#             fin_targets.extend(targets.cpu().detach().numpy().tolist())\n","#             fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","#     return fin_outputs, fin_targets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# outputs, targets = validation()\n","# outputs = np.array(outputs) >= 0.5\n","# accuracy = metrics.accuracy_score(targets, outputs)\n","# f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n","# f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n","# print(f\"Accuracy Score = {accuracy}\")\n","# print(f\"F1 Score (Micro) = {f1_score_micro}\")\n","# print(f\"F1 Score (Macro) = {f1_score_macro}\")"]},{"cell_type":"markdown","metadata":{},"source":["# TRAINING ON MINORITY CLASSES "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import torch\n","# from torch.cuda.amp import autocast\n","# import torch\n","# from torch.cuda.amp import GradScaler\n","\n","# # Define the GradScaler object\n","# scaler = GradScaler()\n","# def train(epoch):\n","#     model.train()\n","#     for _, data in enumerate(train_loader, 0):\n","#         ids = data['ids'].to(device, dtype=torch.long)\n","#         mask = data['mask'].to(device, dtype=torch.long)\n","#         targets = data['targets'].to(device, dtype=torch.float)\n","\n","#         optimizer.zero_grad()\n","\n","#         with autocast():\n","#             outputs = model(ids, mask)\n","#             loss = loss_fn(outputs, targets )\n","\n","#         scaler.scale(loss).backward()\n","#         scaler.step(optimizer)\n","#         scaler.update()\n","\n","#         if _ % 500 == 0:\n","#             print(f'Epoch: {epoch}, Loss: {loss.item()}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# RUNNING ON TEST SET"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def predict():\n","    model_news.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for _, data in enumerate(majority, 0):\n","            ids = data['ids'].to(device, dtype=torch.long)\n","            mask = data['mask'].to(device, dtype=torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","\n","            outputs = model_news(ids, mask)\n","            predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","    return predictions\n","\n","# Get predictions\n","test_predictions = predict()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_csv=pd.read_csv('/kaggle/input/kriti-24/train.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_csv"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Assuming you have two DataFrames: df and train_csv\n","# Add the 'Id' column from train_csv to df\n","df['Id'] = train_csv['Id']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Convert predictions to binary (True/False)\n","binary_predictions = np.array(test_predictions) >= 0.5\n","\n","# Convert boolean values to integers (1/0)\n","binary_predictions_int = binary_predictions.astype(int)\n","\n","# Create a DataFrame for submission\n","submission_df = pd.DataFrame(binary_predictions_int, columns=target_cols)\n","submission_df.insert(0, 'Text', df.Text)\n","submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["target_cols2 = [col for col in df.columns if col not in ['Text','Title','Abstract','Id']]\n","len(target_cols2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Convert predictions to binary (True/False)\n","binary_predictions = np.array(test_predictions) >= 0.5\n","\n","# Convert boolean values to integers (1/0)\n","binary_predictions_int = binary_predictions.astype(int)\n","\n","# Create a DataFrame for submission\n","submission_df = pd.DataFrame(binary_predictions_int, columns=target_cols2)\n","submission_df.insert(0, 'Id', df.Id)\n","submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["template_df = pd.read_csv('/kaggle/input/kriti-24/sample_submission.csv')\n","required_column_order = template_df.columns.tolist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # Ensure that 'Id' is the first column\n","# required_column_order.remove('Id')\n","# required_column_order.insert(0, 'Id')\n","\n","# Reorder your DataFrame columns\n","train_predict = submission_df[required_column_order]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_predict.loc[:, 'Text'] = df['Text'].copy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_predict.drop(['Id'],axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["last_column = train_predict.pop(train_predict.columns[-1])\n","train_predict.insert(0, last_column.name, last_column)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_predict\n","save"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# DOING A PREDICTION "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","# Load the test dataset\n","test_df = pd.read_csv(\"/kaggle/input/kriti-24/test.csv\")\n","\n","# Preprocess the text data\n","test_df['Text'] = test_df['Title'] + ' ' + test_df['Abstract']\n","test_df = test_df.drop(['Title', 'Abstract'], axis=1)\n","test_df['Text']=test_df['Text'].str.lower()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def remove_punct(text):\n","    punctuation =string.punctuation\n","    return text.translate(str.maketrans('' , '',punctuation))\n","test_df['Text']=test_df['Text'].apply(lambda x: remove_punct(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from nltk.corpus import stopwords \n","\",\".join(stopwords.words('english'))\n","STOPWRDS=set(stopwords.words('english'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def remove_stp(Text):\n","    return \" \".join([word for word in Text.split() if word not in STOPWRDS])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_df['Text']=test_df['Text'].apply(lambda x: remove_stp(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["not_needed = [\n","     \"using\", \"results\", \"performance\", \"show\", \"method\", \"approach\",\n","    \"also\", \"based\", \"problem\", \"proposed\", \"two\", \"information\", \"new\", \"large\",\n","    \"different\", \"study\", \"however\",  \"analysis\", \"one\", \"work\", \"used\", \"first\",\n","    \"set\", \"use\", \"existing\", \"present\", \"process\", \"demonstrate\", \"task\", \"general\",\n","    \"several\", \"due\", \"compared\", \"via\", \"moreover\", \"eg\", \"thus\", \"possible\", \"make\",\n","    \"like\", \"important\", \"key\", \"furthermore\", \"give\", \"state\", \"certain\", \"ie\", \"form\",\n","    \"allows\", \"finally\", \"often\", \"even\", \"many\", \"various\", \"well\", \"also\", \"however\",\n","    \"several\", \"due\", \"across\", \"may\", \"without\", \"among\", \"including\", \"particular\",\n","    \"especially\", \"either\", \"often\", \"even\", \"moreover\", \"thus\", \"ie\", \"eg\", \"although\",\n","    \"despite\",\"would\" ,\"within\" ,\"\",\n","]\n","\n","import pandas as pd\n","def not_need(Text):\n","    return \" \".join([word for word in Text.split() if word not in not_needed])\n","\n","test_df['Text'] = test_df['Text'].apply(lambda x:not_need(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class BERTTestDatasets(Dataset):\n","    def __init__(self, df, tokenizer, max_len):\n","        self.df = df\n","        self.max_len = max_len\n","        self.text = df.Text\n","        self.tokenizer = tokenizer\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        \n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n","        }\n","\n","# Create the test dataset\n","result_dataset = BERTTestDatasets(test_df, tokenizer, MAX_LEN)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["result_loader = DataLoader(result_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def predict():\n","    model_news.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for _, data in enumerate(result_loader, 0):\n","            ids = data['ids'].to(device, dtype=torch.long)\n","            mask = data['mask'].to(device, dtype=torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","\n","            outputs = model_news(ids, mask)\n","            predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","    return predictions\n","\n","# Get predictions\n","test_predictions = predict()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Convert predictions to binary (True/False)\n","binary_predictions = np.array(test_predictions) >= 0.5\n","\n","# Convert boolean values to integers (1/0)\n","binary_predictions_int = binary_predictions.astype(int)\n","\n","# Create a DataFrame for submission\n","submission_df = pd.DataFrame(binary_predictions_int, columns=target_cols)\n","submission_df.insert(0, 'Id', test_df.Id)\n","submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["target_cols2 = [col for col in df.columns if col not in ['Text','Title','Abstract']]\n","len(target_cols2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Convert predictions to binary (True/False)\n","binary_predictions = np.array(test_predictions) >= 0.5\n","\n","# Convert boolean values to integers (1/0)\n","binary_predictions_int = binary_predictions.astype(int)\n","\n","# Create a DataFrame for submission\n","submission_df = pd.DataFrame(binary_predictions_int, columns=target_cols2)\n","submission_df.insert(0, 'Id', test_df.Id)\n","submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["template_df = pd.read_csv('/kaggle/input/kriti-24/sample_submission.csv')\n","required_column_order = template_df.columns.tolist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Ensure that 'Id' is the first column\n","required_column_order.remove('Id')\n","required_column_order.insert(0, 'Id')\n","\n","# Reorder your DataFrame columns\n","submission_df = submission_df[required_column_order]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# SUBMISSION_ORDER_NEW is the main submission file"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission_df\n","submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4365552,"sourceId":7497287,"sourceType":"datasetVersion"},{"datasetId":4399782,"sourceId":7554287,"sourceType":"datasetVersion"},{"datasetId":4399713,"sourceId":7559219,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
